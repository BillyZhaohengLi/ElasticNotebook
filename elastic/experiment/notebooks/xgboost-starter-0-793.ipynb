{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Starter - LB 0.793\n",
    "In this notebook we build and train an XGBoost model using @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. This XGB model achieves CV 0.792 LB 0.793! When training with XGB, we use a special XGB dataloader called `DeviceQuantileDMatrix` which uses a small GPU memory footprint. This allows us to engineer more additional columns and train with more rows of data. Our feature engineering is performed using [RAPIDS][5] on the GPU to create new features quickly.\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n",
    "[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n",
    "[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "[5]: https://rapids.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_446097/562980197.py\", line 3, in <module>\n",
      "    import cupy, cudf # GPU libraries\n",
      "ModuleNotFoundError: No module named 'cupy'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 720, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 663, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 600, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"/srv/local/data/elastic-notebook/venv/lib/python3.8/site-packages/stack_data/core.py\", line 164, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "# LOAD LIBRARIES\n",
    "import pandas as pd, numpy as np # CPU libraries\n",
    "import cupy, cudf # GPU libraries\n",
    "import matplotlib.pyplot as plt, gc, os\n",
    "\n",
    "print('RAPIDS version',cudf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:29.544564Z",
     "iopub.status.busy": "2022-06-01T23:23:29.54422Z",
     "iopub.status.idle": "2022-06-01T23:23:29.548965Z",
     "shell.execute_reply": "2022-06-01T23:23:29.547871Z",
     "shell.execute_reply.started": "2022-06-01T23:23:29.544529Z"
    }
   },
   "outputs": [],
   "source": [
    "# VERSION NAME FOR SAVED MODEL FILES\n",
    "VER = 1\n",
    "\n",
    "# TRAIN RANDOM SEED\n",
    "SEED = 42\n",
    "\n",
    "# FILL NAN VALUE\n",
    "NAN_VALUE = -127 # will fit in int8\n",
    "\n",
    "# FOLDS PER MODEL\n",
    "FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Feature Engineer Train Data\n",
    "We will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][3] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n",
    "[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n",
    "[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "[5]: https://rapids.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:29.551112Z",
     "iopub.status.busy": "2022-06-01T23:23:29.550521Z",
     "iopub.status.idle": "2022-06-01T23:23:50.757922Z",
     "shell.execute_reply": "2022-06-01T23:23:50.757091Z",
     "shell.execute_reply.started": "2022-06-01T23:23:29.551076Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_file(path = '', usecols = None):\n",
    "    # LOAD DATAFRAME\n",
    "    if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n",
    "    else: df = cudf.read_parquet(path)\n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    df.S_2 = cudf.to_datetime( df.S_2 )\n",
    "    # SORT BY CUSTOMER AND DATE (so agg('last') works correctly)\n",
    "    #df = df.sort_values(['customer_ID','S_2'])\n",
    "    #df = df.reset_index(drop=True)\n",
    "    # FILL NAN\n",
    "    df = df.fillna(NAN_VALUE) \n",
    "    print('shape of data:', df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print('Reading train data...')\n",
    "TRAIN_PATH = '../input/amex-data-integer-dtypes-parquet-format/train.parquet'\n",
    "train = read_file(path = TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:50.760676Z",
     "iopub.status.busy": "2022-06-01T23:23:50.760118Z",
     "iopub.status.idle": "2022-06-01T23:23:50.987326Z",
     "shell.execute_reply": "2022-06-01T23:23:50.986452Z",
     "shell.execute_reply.started": "2022-06-01T23:23:50.760639Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:50.988863Z",
     "iopub.status.busy": "2022-06-01T23:23:50.988499Z",
     "iopub.status.idle": "2022-06-01T23:23:52.150336Z",
     "shell.execute_reply": "2022-06-01T23:23:52.149507Z",
     "shell.execute_reply.started": "2022-06-01T23:23:50.988828Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_and_feature_engineer(df):\n",
    "    # FEATURE ENGINEERING FROM \n",
    "    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "\n",
    "    test_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "\n",
    "    df = cudf.concat([test_num_agg, test_cat_agg], axis=1)\n",
    "    del test_num_agg, test_cat_agg\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = process_and_feature_engineer(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:52.152867Z",
     "iopub.status.busy": "2022-06-01T23:23:52.151491Z",
     "iopub.status.idle": "2022-06-01T23:23:53.116769Z",
     "shell.execute_reply": "2022-06-01T23:23:53.115883Z",
     "shell.execute_reply.started": "2022-06-01T23:23:52.152828Z"
    }
   },
   "outputs": [],
   "source": [
    "# ADD TARGETS\n",
    "targets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "targets = targets.set_index('customer_ID')\n",
    "train = train.merge(targets, left_index=True, right_index=True, how='left')\n",
    "train.target = train.target.astype('int8')\n",
    "del targets\n",
    "\n",
    "# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n",
    "train = train.sort_index().reset_index()\n",
    "\n",
    "# FEATURES\n",
    "FEATURES = train.columns[1:-1]\n",
    "print(f'There are {len(FEATURES)} features!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train XGB\n",
    "We will train using `DeviceQuantileDMatrix`. This has a very small GPU memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:53.118704Z",
     "iopub.status.busy": "2022-06-01T23:23:53.118158Z",
     "iopub.status.idle": "2022-06-01T23:23:53.217648Z",
     "shell.execute_reply": "2022-06-01T23:23:53.21687Z",
     "shell.execute_reply.started": "2022-06-01T23:23:53.118667Z"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD XGB LIBRARY\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "print('XGB Version',xgb.__version__)\n",
    "\n",
    "# XGB MODEL PARAMETERS\n",
    "xgb_parms = { \n",
    "    'max_depth':4, \n",
    "    'learning_rate':0.05, \n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.6, \n",
    "    'eval_metric':'logloss',\n",
    "    'objective':'binary:logistic',\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor':'gpu_predictor',\n",
    "    'random_state':SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:53.219242Z",
     "iopub.status.busy": "2022-06-01T23:23:53.218898Z",
     "iopub.status.idle": "2022-06-01T23:23:53.230776Z",
     "shell.execute_reply": "2022-06-01T23:23:53.229929Z",
     "shell.execute_reply.started": "2022-06-01T23:23:53.219208Z"
    }
   },
   "outputs": [],
   "source": [
    "# NEEDED WITH DeviceQuantileDMatrix BELOW\n",
    "class IterLoadForDMatrix(xgb.core.DataIter):\n",
    "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "        self.it = 0 # set iterator to 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        '''Reset the iterator'''\n",
    "        self.it = 0\n",
    "\n",
    "    def next(self, input_data):\n",
    "        '''Yield next batch of data.'''\n",
    "        if self.it == self.batches:\n",
    "            return 0 # Return 0 when there's no more batch.\n",
    "        \n",
    "        a = self.it * self.batch_size\n",
    "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
    "        dt = cudf.DataFrame(self.df.iloc[a:b])\n",
    "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
    "        self.it += 1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:53.232589Z",
     "iopub.status.busy": "2022-06-01T23:23:53.232033Z",
     "iopub.status.idle": "2022-06-01T23:23:53.247106Z",
     "shell.execute_reply": "2022-06-01T23:23:53.246228Z",
     "shell.execute_reply.started": "2022-06-01T23:23:53.232551Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/kyakovlev\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n",
    "def amex_metric_mod(y_true, y_pred):\n",
    "\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:23:53.252147Z",
     "iopub.status.busy": "2022-06-01T23:23:53.251866Z",
     "iopub.status.idle": "2022-06-01T23:25:30.597781Z",
     "shell.execute_reply": "2022-06-01T23:25:30.596767Z",
     "shell.execute_reply.started": "2022-06-01T23:23:53.252122Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = []\n",
    "oof = []\n",
    "train = train.to_pandas() # free GPU memory\n",
    "TRAIN_SUBSAMPLE = 1.0\n",
    "gc.collect()\n",
    "\n",
    "skf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "for fold,(train_idx, valid_idx) in enumerate(skf.split(\n",
    "            train, train.target )):\n",
    "    \n",
    "    # TRAIN WITH SUBSAMPLE OF TRAIN FOLD DATA\n",
    "    if TRAIN_SUBSAMPLE<1.0:\n",
    "        np.random.seed(SEED)\n",
    "        train_idx = np.random.choice(train_idx, \n",
    "                       int(len(train_idx)*TRAIN_SUBSAMPLE), replace=False)\n",
    "        np.random.seed(None)\n",
    "    \n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
    "    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n",
    "    print('#'*25)\n",
    "    \n",
    "    # TRAIN, VALID, TEST FOR FOLD K\n",
    "    Xy_train = IterLoadForDMatrix(train.loc[train_idx], FEATURES, 'target')\n",
    "    X_valid = train.loc[valid_idx, FEATURES]\n",
    "    y_valid = train.loc[valid_idx, 'target']\n",
    "    \n",
    "    dtrain = xgb.DeviceQuantileDMatrix(Xy_train, max_bin=256)\n",
    "    dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
    "    \n",
    "    # TRAIN MODEL FOLD K\n",
    "    model = xgb.train(xgb_parms, \n",
    "                dtrain=dtrain,\n",
    "                evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "                num_boost_round=9999,\n",
    "                early_stopping_rounds=100,\n",
    "                verbose_eval=100) \n",
    "    model.save_model(f'XGB_v{VER}_fold{fold}.xgb')\n",
    "    \n",
    "    # GET FEATURE IMPORTANCE FOR FOLD K\n",
    "    dd = model.get_score(importance_type='weight')\n",
    "    df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n",
    "    importances.append(df)\n",
    "            \n",
    "    # INFER OOF FOLD K\n",
    "    oof_preds = model.predict(dvalid)\n",
    "    acc = amex_metric_mod(y_valid.values, oof_preds)\n",
    "    print('Kaggle Metric =',acc,'\\n')\n",
    "    \n",
    "    # SAVE OOF\n",
    "    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n",
    "    df['oof_pred'] = oof_preds\n",
    "    oof.append( df )\n",
    "    \n",
    "    del dtrain, Xy_train, dd, df\n",
    "    del X_valid, y_valid, dvalid, model\n",
    "    _ = gc.collect()\n",
    "    \n",
    "print('#'*25)\n",
    "oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
    "acc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
    "print('OVERALL CV Kaggle Metric =',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:25:30.600923Z",
     "iopub.status.busy": "2022-06-01T23:25:30.599137Z",
     "iopub.status.idle": "2022-06-01T23:25:30.751268Z",
     "shell.execute_reply": "2022-06-01T23:25:30.750376Z",
     "shell.execute_reply.started": "2022-06-01T23:25:30.600878Z"
    }
   },
   "outputs": [],
   "source": [
    "# CLEAN RAM\n",
    "del train\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save OOF Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_xgb = pd.read_parquet(TRAIN_PATH, columns=['customer_ID']).drop_duplicates()\n",
    "oof_xgb['customer_ID_hash'] = oof_xgb['customer_ID'].apply(lambda x: int(x[-16:],16) ).astype('int64')\n",
    "oof_xgb = oof_xgb.set_index('customer_ID_hash')\n",
    "oof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\n",
    "oof_xgb = oof_xgb.sort_index().reset_index(drop=True)\n",
    "oof_xgb.to_csv(f'oof_xgb_v{VER}.csv',index=False)\n",
    "oof_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OOF PREDICTIONS\n",
    "plt.hist(oof_xgb.oof_pred.values, bins=100)\n",
    "plt.title('OOF Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAR VRAM, RAM FOR INFERENCE BELOW\n",
    "del oof_xgb, oof\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:25:30.752879Z",
     "iopub.status.busy": "2022-06-01T23:25:30.752477Z",
     "iopub.status.idle": "2022-06-01T23:25:30.783511Z",
     "shell.execute_reply": "2022-06-01T23:25:30.782316Z",
     "shell.execute_reply.started": "2022-06-01T23:25:30.752824Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = importances[0].copy()\n",
    "for k in range(1,FOLDS): df = df.merge(importances[k], on='feature', how='left')\n",
    "df['importance'] = df.iloc[:,1:].mean(axis=1)\n",
    "df = df.sort_values('importance',ascending=False)\n",
    "df.to_csv(f'xgb_feature_importance_v{VER}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:25:30.78586Z",
     "iopub.status.busy": "2022-06-01T23:25:30.785323Z",
     "iopub.status.idle": "2022-06-01T23:25:31.062929Z",
     "shell.execute_reply": "2022-06-01T23:25:31.062157Z",
     "shell.execute_reply.started": "2022-06-01T23:25:30.785818Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_FEATURES = 20\n",
    "plt.figure(figsize=(10,5*NUM_FEATURES//10))\n",
    "plt.barh(np.arange(NUM_FEATURES,0,-1), df.importance.values[:NUM_FEATURES])\n",
    "plt.yticks(np.arange(NUM_FEATURES,0,-1), df.feature.values[:NUM_FEATURES])\n",
    "plt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and Feature Engineer Test Data\n",
    "We will load @raddar Kaggle dataset from [here][1] with discussion [here][2]. Then we will engineer features suggested by @huseyincot in his notebooks [here][1] and [here][4]. We will use [RAPIDS][5] and the GPU to create new features quickly.\n",
    "\n",
    "[1]: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "[2]: https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514\n",
    "[3]: https://www.kaggle.com/code/huseyincot/amex-catboost-0-793\n",
    "[4]: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "[5]: https://rapids.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:25:31.064756Z",
     "iopub.status.busy": "2022-06-01T23:25:31.064246Z",
     "iopub.status.idle": "2022-06-01T23:25:33.699775Z",
     "shell.execute_reply": "2022-06-01T23:25:33.698995Z",
     "shell.execute_reply.started": "2022-06-01T23:25:31.064719Z"
    }
   },
   "outputs": [],
   "source": [
    "# CALCULATE SIZE OF EACH SEPARATE TEST PART\n",
    "def get_rows(customers, test, NUM_PARTS = 4, verbose = ''):\n",
    "    chunk = len(customers)//NUM_PARTS\n",
    "    if verbose != '':\n",
    "        print(f'We will process {verbose} data as {NUM_PARTS} separate parts.')\n",
    "        print(f'There will be {chunk} customers in each part (except the last part).')\n",
    "        print('Below are number of rows in each part:')\n",
    "    rows = []\n",
    "\n",
    "    for k in range(NUM_PARTS):\n",
    "        if k==NUM_PARTS-1: cc = customers[k*chunk:]\n",
    "        else: cc = customers[k*chunk:(k+1)*chunk]\n",
    "        s = test.loc[test.customer_ID.isin(cc)].shape[0]\n",
    "        rows.append(s)\n",
    "    if verbose != '': print( rows )\n",
    "    return rows,chunk\n",
    "\n",
    "# COMPUTE SIZE OF 4 PARTS FOR TEST DATA\n",
    "NUM_PARTS = 4\n",
    "TEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'\n",
    "\n",
    "print(f'Reading test data...')\n",
    "test = read_file(path = TEST_PATH, usecols = ['customer_ID','S_2'])\n",
    "customers = test[['customer_ID']].drop_duplicates().sort_index().values.flatten()\n",
    "rows,num_cust = get_rows(customers, test[['customer_ID']], NUM_PARTS = NUM_PARTS, verbose = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:25:33.701423Z",
     "iopub.status.busy": "2022-06-01T23:25:33.701085Z",
     "iopub.status.idle": "2022-06-01T23:26:38.059268Z",
     "shell.execute_reply": "2022-06-01T23:26:38.058458Z",
     "shell.execute_reply.started": "2022-06-01T23:25:33.701396Z"
    }
   },
   "outputs": [],
   "source": [
    "# INFER TEST DATA IN PARTS\n",
    "skip_rows = 0\n",
    "skip_cust = 0\n",
    "test_preds = []\n",
    "\n",
    "for k in range(NUM_PARTS):\n",
    "    \n",
    "    # READ PART OF TEST DATA\n",
    "    print(f'\\nReading test data...')\n",
    "    test = read_file(path = TEST_PATH)\n",
    "    test = test.iloc[skip_rows:skip_rows+rows[k]]\n",
    "    skip_rows += rows[k]\n",
    "    print(f'=> Test part {k+1} has shape', test.shape )\n",
    "    \n",
    "    # PROCESS AND FEATURE ENGINEER PART OF TEST DATA\n",
    "    test = process_and_feature_engineer(test)\n",
    "    if k==NUM_PARTS-1: test = test.loc[customers[skip_cust:]]\n",
    "    else: test = test.loc[customers[skip_cust:skip_cust+num_cust]]\n",
    "    skip_cust += num_cust\n",
    "    \n",
    "    # TEST DATA FOR XGB\n",
    "    X_test = test[FEATURES]\n",
    "    dtest = xgb.DMatrix(data=X_test)\n",
    "    test = test[['P_2_mean']] # reduce memory\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "    # INFER XGB MODELS ON TEST DATA\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(f'XGB_v{VER}_fold0.xgb')\n",
    "    preds = model.predict(dtest)\n",
    "    for f in range(1,FOLDS):\n",
    "        model.load_model(f'XGB_v{VER}_fold{f}.xgb')\n",
    "        preds += model.predict(dtest)\n",
    "    preds /= FOLDS\n",
    "    test_preds.append(preds)\n",
    "\n",
    "    # CLEAN MEMORY\n",
    "    del dtest, model\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:26:38.061347Z",
     "iopub.status.busy": "2022-06-01T23:26:38.060995Z",
     "iopub.status.idle": "2022-06-01T23:26:39.073254Z",
     "shell.execute_reply": "2022-06-01T23:26:39.072485Z",
     "shell.execute_reply.started": "2022-06-01T23:26:38.061312Z"
    }
   },
   "outputs": [],
   "source": [
    "# WRITE SUBMISSION FILE\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test = cudf.DataFrame(index=customers,data={'prediction':test_preds})\n",
    "sub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')[['customer_ID']]\n",
    "sub['customer_ID_hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "sub = sub.set_index('customer_ID_hash')\n",
    "sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
    "sub = sub.reset_index(drop=True)\n",
    "\n",
    "# DISPLAY PREDICTIONS\n",
    "sub.to_csv(f'submission_xgb_v{VER}.csv',index=False)\n",
    "print('Submission file shape is', sub.shape )\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-01T23:26:39.074873Z",
     "iopub.status.busy": "2022-06-01T23:26:39.074437Z",
     "iopub.status.idle": "2022-06-01T23:26:39.799231Z",
     "shell.execute_reply": "2022-06-01T23:26:39.798463Z",
     "shell.execute_reply.started": "2022-06-01T23:26:39.074837Z"
    }
   },
   "outputs": [],
   "source": [
    "# PLOT PREDICTIONS\n",
    "plt.hist(sub.to_pandas().prediction, bins=100)\n",
    "plt.title('Test Predictions')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
